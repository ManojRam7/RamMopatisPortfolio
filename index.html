<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Ram Mopati Portfolio</title>
  <!-- Link to CSS -->
  <link rel="stylesheet" href="css/styles.css">
  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&family=Poppins:wght@300;400;700&display=swap" rel="stylesheet">
  <!-- FontAwesome -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" rel="stylesheet">
  <!-- AOS Animation Library -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/aos/2.3.4/aos.css" rel="stylesheet">
  <style>
    body {
      margin: 0;
      font-family: Arial, sans-serif;
      background-color: #f3f4f6;
    }

    .header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 20px 40px;
      background: linear-gradient(to right, #091d4b, #091e0e);
      color: white;
      position: sticky;
      top: 0;
      z-index: 1000;
    }

    .header h1 {
      margin: 0;
      font-size: 1.8rem;
    }

    .header nav a {
      color: white;
      text-decoration: none;
      margin-left: 20px;
      font-size: 1rem;
      font-weight: bold;
    }

    .header nav a:hover {
      text-decoration: underline;
    }

    .profile-section {
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 100px 40px;
      background: linear-gradient(to right, #6a11cb, #2575fc);
      color: white;
    }

    .profile-pic {
      width: 50%;
      height: 100%;
      object-fit: cover;
      box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);
    }

    .intro-text {
      text-align: right;
      max-width: 50%;
    }

    .intro-text h1 {
      font-size: 3.5rem;
      margin: 20px 0;
    }

    .intro-text p {
      font-size: 1.5rem;
    }

    .section {
      padding: 60px 20px;
    }

    #about {
      background-color: #ede8e4fa; /* Light Blue */
      text-align: left;
    }

    #work-experience {
      background-color: #e6f7e6; /* Light Green */
    }

    #projects {
      background-color: #fffaf0; /* Light Yellow */
    }
   
    .projects-container {
      display: flex;
      justify-content: center;
      gap: 30px;
      flex-wrap: wrap;
    }

    .project-card {
      background: white;
      border-radius: 10px;
      box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
      padding: 50px;
      /*max-width: 350px; */
      text-align: center;
      transition: transform 0.3s, box-shadow 0.3s;
    }

    .project-card:hover {
      transform: translateY(-10px);
      box-shadow: 0 8px 20px rgba(0, 0, 0, 0.2);
    }

    .project-card img {
      max-width: 100%;
      border-radius: 5px;
      margin-bottom: 15px;
    }

    #projects .projects-container {
      gap: 40px;
    }

    .project-card {
    /*  max-width: 400px;     */
    }
  </style>
</head>
<body>
  <header class="header">
    <h1>Ram Mopati</h1>
    <nav>
      <a href="#about">About</a>
      <a href="#work-experience">Work Experience</a>
      <a href="#projects">Projects</a>
      <a href="#resume">Resume</a>
      <a href="#contact">Contact</a>
    </nav>
  </header>

  <section class="profile-section">
    <img src="assets/your-photo.jpg" alt="Your Photo" class="profile-pic">
    <div class="intro-text">
      <h1>ðŸ‘‹ Welcome to My Data Science Portfolio... </h1>
      <p>  </p>
      <p>  </p>
      <p>  </p>
      <h2>Hi, I'm Ram Mopati, An Aspiring Data Scientist,</h2>
      <h3>Pursuing <strong>Master of Science in Data Science at Coventry University</strong>, United Kingdom.</h3>
    </div>
  </section>

  <section id="about" class="section">
    <h2 data-aos="fade-up">About Me</h2>
    <p data-aos="fade-up">
      My name is <strong>ManojRam Mopati</strong>, a data-driven professional currently pursuing a <strong>Master of Science in Data Science at Coventry University</strong>, Big Data Analytics, Machine Learning and other Modules included.
    </p>
    <p data-aos="fade-up">
      I began my career at the service-based company <strong>Infosys Ltd</strong> in the comapny role of <strong>Software Quality Engineer</strong>, Where I initially worked as a client-facing role <strong>Regression Test Analyst</strong> for few days before transitioning into a client-facing role <strong>Data Analyst</strong>, where I worked with large-scale datasets to generate insights, automate reporting pipelines, and deliver high-impact dashboards.
    </p>

    <p data-aos="fade-up">
      My professional work includes building <strong>Power BI dashboards</strong> for 5 business units, performing SQL-based data extraction and transformation, conducting <strong>exploratory data analysis (EDA)</strong>, and leveraging <strong>PySpark in Azure Databricks</strong> to streamline data processing workflows.
    </p>
  
    <p data-aos="fade-up">
      I have also developed <strong>end-to-end data science and machine learning projects</strong> in domains such as healthcare, finance, and real estate. These include predictive modeling, classification, recommendation systems, and deep learning applicationsâ€”many of which are showcased in this portfolio.
    </p>
  
    <p data-aos="fade-up">
      I am passionate about <strong>data storytelling</strong>â€”translating complex datasets into insights that drive business decisions. I thrive in collaborative, agile environments and enjoy working closely with cross-functional teams.
    </p>
  
    <p data-aos="fade-up">
      I am currently seeking <strong>data science internships or part-time opportunities</strong> in the UK or Europe where I can contribute using my technical skills in <strong>SQL, Python, Power BI, and cloud analytics platforms</strong> like Azure.
    </p>
    <p data-aos="fade-up">
      Outside of work, I enjoy exploring new technologies, competing in data science challenges, and contributing to open-source projects. Iâ€™m committed to continuous learning and stay updated through online courses and workshops.
    </p>
    <p data-aos="fade-up">
      This portfolio reflects my passion and capability in <strong>analyzing data, building solutions, and communicating insights</strong> effectively. Each project is a step forward in my journey to becoming a well-rounded data professional.
    </p>
    


    <p data-aos="fade-up">
      <strong>Skills & Tools:</strong><br>
      Python, SQL,data collection, data analysis, EDA, Statistical analysis, and visualization libraries, Power BI, Scikit-learn, TensorFlow, PySpark, Databricks, Microsoft Azure, Machine Learning, Deep Learning, NLP, Time series, Azure DevOps.<br>
      I also have experience with cloud platforms like <strong>GCP, Streamlit Community Cloud, AWS, and Azure</strong> for model deployment and managing data pipelines.
    </p>
  
    <p data-aos="fade-up">
      ðŸ“Š Feel free to explore my github code repos and <strong>get in touch if youâ€™re looking for a dedicated Data Science intern ready to make an impact!</strong>
    </p>

  </section>
    <!-- --------------------------------------------------------------  -->
  <section id="work-experience" class="section">
    <h2 data-aos="fade-up">Work Experience</h2>
    <div class="work-container">
      <div class="work-card" data-aos="fade-up" data-aos-delay="200">
        <img src="assets/work3.png" alt="Data Analyst">
        <h3>Infosys Ltd (Company Role: Software Quality Engineer), Banglore, India. </h3>    
        <h4>Client: UK Insurance Project | Data Analyst </h4>
        <h5>3+ years of experience | Feb 2022 - May 2025</h5>
        <p class="work-summary">
        <!-- Replace your current summary paragraph with this -->
        <p class="work-summary">
          As a Data Analyst, I played a key role in transforming raw insurance and policy data into actionable business insights by collaborating with Business Analysts, Scrum Leads, and product managers to meet evolving business requirements. I conducted in-depth exploratory data analysis (EDA), built SQL-based reports, and designed interactive dashboards using Power BI that empowered business teams to make informed, data-driven decisions.
          My work involved automating reporting pipelines using Azure Databricks and PySpark to enhance the efficiency of data processing tasks, especially for large-scale claim and policy datasets (10M+ rows). I also developed Python scripts for data transformation, anomaly detection, and analytical modeling to support strategic decisions.
          Additionally, I was responsible for creating and maintaining clear documentation of data processes, validation rules, and business logic to ensure transparency, reusability, and audit-readiness. I actively participated in Agile/Scrum ceremoniesâ€”including sprint planning, reviews, and retrospectivesâ€”which enabled collaborative progress tracking and iterative delivery of analytics solutions.
          These contributions collectively led to improved data visibility, a 50% reduction in manual reporting efforts, faster reporting cycles, and more consistent stakeholder engagement through high-quality, insight-driven deliverables.
      
        </p>
        <h4>Key Responsibilities:</h4>
        <ul class="work-bullets">
          <li><i class="fas fa-chart-bar"></i> <strong>Designed and deployed interactive Power BI dashboards</strong> for 5 business units, enabling faster and more informed decision-making.</li>

          <li><i class="fas fa-search"></i> <strong>Performed exploratory data analysis (EDA)</strong> on policy and claim datasets to uncover trends, anomalies, and patterns driving business insights.</li>

          <li><i class="fas fa-database"></i> <strong>Built complex SQL-based reports</strong> using Oracle SQL Developer to extract, transform, and analyze large-scale datasets (10M+ rows).</li>

          <li><i class="fas fa-users"></i> <strong>Collaborated with Business Analysts and Scrum Leads</strong> to gather requirements and deliver analytics solutions aligned with project KPIs.</li>

          <li><i class="fas fa-clipboard-list"></i> <strong>Contributed to Agile/Scrum ceremonies</strong>, including sprint planning and reviews, improving team alignment and delivery cycles.</li>

          <li><i class="fas fa-analytics"></i> <strong>Used Azure Databricks with PySpark</strong> to automate data processing pipelines, optimizing performance for high-volume claim data.</li>

          <li><i class="fas fa-code"></i> <strong>Developed Python scripts</strong> for data cleaning, transformation, and anomaly detection to support business reporting workflows.</li>

          <li><i class="fas fa-file-alt"></i> <strong>Documented data logic, validation rules, and transformation flows</strong> to ensure transparency, reproducibility, and smooth handovers.</li>

          <li><i class="fas fa-chart-line"></i> <strong>Presented analytical insights and dashboards</strong> to business stakeholders, translating data into strategic decisions in weekly reviews.</li>

          <li><i class="fas fa-shield-alt"></i> <strong>Implemented data quality checks</strong> to maintain accuracy and reliability across reporting deliverables and dashboards.</li>

          <li><i class="fas fa-cogs"></i> <strong>Automated 4+ reporting pipelines</strong> using Databricks and SQL, reducing manual workload by 50% and improving efficiency.</li>

          <li><i class="fas fa-lightbulb"></i> <strong>Proactively identified process gaps</strong> in data workflows and implemented solutions that improved reporting accuracy and speed.</li>

          <li><i class="fas fa-tasks"></i> <strong>Handled multiple concurrent analytics tasks</strong> within Agile sprints, delivering high-quality solutions under tight deadlines.</li>

          <li><i class="fas fa-comments"></i> <strong>Engaged in continuous learning</strong> through self-study, projects, and certifications in data science, cloud, and machine learning technologies.</li>

        </p>
        <p><strong>Tools:</strong>Oracle SQL Developer, Microsoft Power BI, Python, Pyspark, Azure Databricks, Azure Devops.</p>
      </div>
      <!--
      </div>
      <div class="work-card" data-aos="fade-up" data-aos-delay="0">
        <img src="assets/work1.png" alt="QA Engineer">
        
        <h3>Infosys Ltd, Banglore, India. </h3>
        <h4>Role : Software Quality Engineer, </h4>
        <h4>1 year of experience.</h4>
        <p class="work-summary">
        <strong>As a Software QA Engineer, I played a key role in ensuring the quality and reliability of software products through rigorous testing methodologies. In my role, I collaborated closely with cross-functional teams in Agile/Scrum environments, actively participating in sprint planning and retrospectives. My contributions significantly enhanced product quality, reduced release cycles, and improved overall team performance.</strong>
        </p>
        <h4>Key Responsibilities:</h4>
        <ul class="work-bullets">
          <li><i class="fas fa-vial"></i> <strong>Executed automation, regression, and functional testing</strong> across client applications, ensuring high-quality deliverables throughout the SDLC.</li>
          <li><i class="fas fa-code"></i> <strong>Developed and maintained robust test scripts</strong> in FLAU-UI using Selenium C# and Cucumber BDD, improving test reliability and coverage.</li>
          <li><i class="fas fa-database"></i> <strong>Wrote complex SQL queries</strong> and utilized Oracle SQL Developer to fetch required test data.</li>
          <li><i class="fas fa-bug"></i> <strong>Managed bug reporting and documentation</strong> in ServiceNow, accelerating issue resolution and improving team efficiency.</li>
          <li><i class="fas fa-cogs"></i> <strong>Leveraged Azure DevOps</strong> for CI/CD pipeline management, test planning, sprint tracking, and automated test result uploads.</li>
          <li><i class="fas fa-users"></i> <strong>Collaborated in Agile/Scrum teams</strong>, actively contributing to sprint planning, retrospectives, and cross-functional decision-making.</li>
          
        </ul>      
        <p><strong>Tools:</strong> Selenium C#, FLAU-UI, Cucumber BDD, Oracle SQL Developer, Azure DevOps, Excel Analysis, Azure Devops,Visual Studio code 2022.</p>
      </div>
    -->
    </div>
  </section>
    <!-- --------------------------------------------------------------  -->

  <section id="projects" class="section">
    <h2 data-aos="fade-up">Projects</h2>
    <div class="projects-container">
      <div class="project-card" data-aos="fade-up">
        <img src="assets/project0.png" alt="Project Image">

        <h3>Enterprise Customer Churn or Retention Analytics Platform</h3>
        <h4><strong>Business Impact Summary:</strong></h4>
        <p>Developed a production-ready machine learning web application that predicts customer churn for telecom companies with 99%+ accuracy. Built an end-to-end MLOps platform featuring real-time predictions, automated deployment, and comprehensive data analysis to help businesses proactively identify at-risk customers and implement retention strategies. The application combines advanced machine learning algorithms with modern web technologies and cloud infrastructure for scalable, reliable performance.</p>
        <ul>
        <h4><strong>Technical Features:</strong></h4>
        <li><strong>Data Processing Pipeline:</strong> Implements comprehensive data preprocessing with custom transformers for categorical encoding, numerical scaling, and feature engineering on 440K+ customer records.</li>
  
        <li><strong>Machine Learning Models:</strong> Trained and compared multiple algorithms including Random Forest, XGBoost, LightGBM, and SVM, achieving consistent 99%+ ROC-AUC scores.</li>
  
        <li><strong>Exploratory Data Analysis (EDA):</strong> Conducted thorough data analysis using Sweetviz and ydata-profiling to understand customer behavior patterns and feature relationships.</li>
  
        <li><strong>Model Optimization:</strong> Applied hyperparameter tuning with GridSearchCV and cross-validation techniques to maximize model performance and reliability.</li>
  
        <li><strong>REST API Development:</strong> Built FastAPI backend with Pydantic models for data validation, supporting both single and batch predictions with comprehensive error handling.</li>
        
        <li><strong>API Testing & Validation:</strong> Performed comprehensive endpoint testing using Postman to validate API functionality, request/response schemas, and error handling scenarios.</li>
        
        <li><strong>Web Interface:</strong> Created responsive HTML frontend with Jinja2 templating for real-time customer churn predictions through user-friendly forms.</li>
  
        <li><strong>Docker Containerization:</strong> Containerized application with optimized Dockerfile and automated Docker image builds pushed to Docker Hub registry for version control and distribution.</li>
  
        <li><strong>Azure Cloud Deployment:</strong> Deployed containerized application on Azure Container Apps pulling from Docker Hub with auto-scaling and managed infrastructure.</li>
  
        <li><strong>CI/CD Pipeline:</strong> Implemented GitHub Actions workflow for automated testing, Docker image building, registry publishing, and seamless cloud deployment.</li>
  
        <li><strong>Testing Framework:</strong> Comprehensive test suite using pytest covering API endpoints and data preprocessing functionality.</li>
        
        <li><strong>Interactive Development:</strong> Jupyter Notebooks provide detailed model training, evaluation, and comparison with visualizations for transparency.</li>
  
        <li><strong>Production Monitoring:</strong> Health check endpoints and model reload functionality for production maintenance and updates.</li>
  
        <li><strong>Performance:</strong> Achieved 99.99% ROC-AUC score with Random Forest model on large-scale telecom dataset.</li>
</ul>

<p><strong>Tools:</strong> Python, FastAPI, Scikit-learn, XGBoost, LightGBM, Pandas, NumPy, Docker, Docker Hub, Azure Container App, CI/CD Pipelines, GitHub Actions, Postman, Jupyter Notebook, Matplotlib, Seaborn, Pytest, Jinja2, Pydantic, Git, HTML.</p>
        
        <div class="project-links">
          <a href="https://telecomchurnazurewebapp-bjb4f4drcqewc5e2.canadacentral-01.azurewebsites.net" target="_blank" class="project-btn">AZURE APP</a>
          <a href="https://github.com/ManojRam7/CustomerChurn_Prediction" target="_blank" class="project-btn">Source Code</a>
        </div>
      </div>


      <!-- --------------------------------------------------------------  -->

      <div class="project-card" data-aos="fade-up">
        <img src="assets/project3.png" alt="Project Image">

        <h3>Agricultural Disease Detection System</h3>
        <h4><strong>Business Impact Summary:</strong></h4>
        <p>
    Developed a robust deep learning application to classify potato leaf diseases from image data, empowering farmers and agricultural professionals with early detection and effective disease management. This project leverages advanced computer vision and neural network techniques to streamline the identification of common potato diseases (such as early blight and late blight) from uploaded images, providing fast and accurate results for practical field use.
  </p>
        <ul>
          <h4><strong>Technical Features:</strong></h4>
          
          <li><strong>Comprehensive Image Data Pipeline:</strong> Loaded, preprocessed, and augmented a large, real-world dataset of potato leaf images (healthy and diseased) to ensure robust model training and testing.</li> 
          
          <li><strong>Exploratory Data Analysis (EDA):</strong> Performed in-depth EDA to understand class distributions, visualize disease patterns, and guide model development.</li>
          
          <li><strong>Image Preprocessing:</strong> Applied transformations such as resizing, normalization, and augmentation (rotation, flipping, etc.) to enhance model generalization and performance.</li> 
          
          <li><strong>Deep Learning Model Training:</strong> Built and trained state-of-the-art convolutional neural networks (CNNs) using TensorFlow and Keras, achieving high classification accuracy (94%) on test data.</li>
          
          <li><strong>Performance Visualization:</strong> Visualized training/validation accuracy and loss curves, as well as confusion matrices, to evaluate and interpret model effectiveness.</li> 
          
          <li><strong>Interactive Notebooks:</strong> Documented the entire workflow in Jupyter Notebooks, including code, visualizations, and step-by-step explanations for transparency and reproducibility.</li> 
          <li>
          <strong>Result Interpretation:</strong> Provided clear output of predicted disease class along with confidence scores for each prediction, aiding user decision-making.
          </li>
          <li>
          <strong>Web Application Deployment:</strong> Deployed the trained model as an interactive web application using Streamlit, allowing users to upload images and receive instant predictions.
          </li>
          <li>
          <strong>API Integration:</strong> Developed a FastAPI backend to serve model predictions via RESTful endpoints, supporting scalable and cloud-ready deployment.
          </li>
          <li>
          <strong>Export and Real-World Deployment:</strong> Supported exporting trained models for integration into real-world or mobile applications, enabling practical field use.
          </li>
          <li>
          <strong>Cloud & Containerization Ready:</strong> Project is structured for easy Dockerization and deployment to cloud platforms such as Azure, AWS, or GCP.
          </li>
          <li>
          <strong>Code Quality & Best Practices:</strong> Utilized modular code structure, requirements files, and version control for maintainability and collaboration.
          </li>
          <li>
          <strong>Reproducibility & Documentation:</strong> Provided detailed documentation and Jupyter Notebooks for transparency, reproducibility, and ease of understanding.
          </li>
          

        <p><strong>Tools:</strong>Python, TensorFlow, Keras, OpenCV, Numpy, Pandas, Scipy, Matplotlib, Seaborn, Scikit-learn, Streamlit, FastAPI, Uvicorn, Jupyter Notebook, Request, Threading, Visualization, Deep Learning, CNN, Streamlit Community Cloud. </p>
        
        <div class="project-links">
          <a href="https://potatodisease-classifier-app.streamlit.app" target="_blank" class="project-btn">STREAMLIT APP</a>
          <a href="https://github.com/ManojRam7/PotatoDisease_Classifier" target="_blank" class="project-btn">Source Code</a>
        </div>
      </div>

     <!-- --------------------------------------------------------------  -->


      <div class="project-card" data-aos="fade-up">
        <img src="assets/project6.png" alt="Project Image">
        <h3>Financial Risk Assessment & Credit Scoring Platform</h3>
        <h4><strong>Business Impact Summary:</strong></h4>
        <p>Developed a machine learning application that predicts loan approval outcomes based on applicant data, assisting financial institutions with risk assessment and streamlined decision-making. Leveraging advanced data processing techniques and predictive modeling, this project automates the evaluation of loan applications using key financial and demographic features, providing rapid and reliable approval predictions for practical business use.</p>
        <ul>
          <h4><strong>Technical Feature:</strong></h4>
          <li><strong>Data Ingestion:</strong> Loads and preprocesses real-world loan application datasets for robust model training and testing.</li> 
          
          <li><strong>Dataset Preparation:</strong> Utilizes comprehensive datasets with features relevant to loan approval, such as applicant income, credit history, employment status, and property details.</li> 
          
          <li><strong>Exploratory Data Analysis (EDA):</strong> Performs EDA to understand feature distributions, correlations, and visualizes important data patterns.</li> 
          
          <li><strong>Data Preprocessing:</strong> Applies normalization, encoding, and feature engineering to enhance model performance and handle missing values.</li> 
          
          <li><strong>Model Training:</strong> Implements state-of-the-art machine learning algorithms (e.g., logistic regression, decision trees, random forest, gradient boosting) to classify applications as approved or denied.</li> 
          
          <li><strong>Performance Visualization:</strong> Visualizes training and validation metrics, ROC curves, and confusion matrices to assess model effectiveness.</li> 
          
          <li><strong>Interactive Notebooks:</strong> Jupyter Notebooks provide step-by-step documentation, code, and visualizations for transparency and reproducibility.</li> 
          
          <li><strong>Result Interpretation:</strong> Offers clear output of predicted loan status along with probability/confidence scores for each application.</li> 
          
          <li><strong>Export and Deployment:</strong> Supports exporting trained models for integration with web or mobile applications, including demonstration via Streamlit Community Cloud.</li> 
          <li><strong>Performance:</strong> Achieved accuracy of 92%.</li>
        </ul>

        <p><strong>Tools:</strong>Jupyter Notebook, Python, Scikit-Learn, NumPy, Pandas, Matplotlib/Seaborn, Data Visualization, Machine Learning, Streamlit Community Cloud. </p>
        
        <div class="project-links">
          <a href="https://loanapprovalprediction-app.streamlit.app" target="_blank" class="project-btn">STREAMLIT APP</a>
          <a href="https://github.com/ManojRam7/LoanApproval_Prediction" target="_blank" class="project-btn">Source Code</a>
        </div>
      </div>


     <!-- --------------------------------------------------------------  -->

      <div class="project-card" data-aos="fade-up">
        <img src="assets/project1.png" alt="Project Image">
        <h3>Luxury Stones Market Valuation Engine</h3>
        
        <h4><strong>Business Impact Summary:</strong></h4>
        <p>Developed a machine learning project designed to estimate gemstone prices based on their characteristics such as carat, depth, table, dimensions, cut, color, and clarity.The project features a complete data pipeline, from data ingestion and preprocessing to advanced model training and deployment.</p>

      
      <ul>
        <h4><strong>Technical Features:</strong></h4>
        <li><strong>Data Ingestion:</strong> Utilizes Kaggle's Gemstone dataset, which includes various gemstone attributes and their corresponding prices.</li>
        
        <li><strong>Exploratory Data Analysis (EDA):</strong> Conducts thorough EDA to understand data distributions, relationships, and potential outliers, using visualizations like scatter plots, histograms, and box plots.</li>
        
        <li><strong>Feature Engineering:</strong> Implements feature engineering techniques to create new features, such as calculating volume from dimensions, and applies transformations to improve model performance.</li>
        
        <li><strong>Data Preprocessing:</strong> Handles missing values, scales numerical features, and encodes categorical variables to prepare the dataset for modeling.</li>
        
        <li><strong>Model Training:</strong> Employs a variety of regression algorithms, including CatBoost, XGBoost, and KNN, to predict gemstone prices. These models are combined using a Voting Regressor to enhance accuracy.</li>
        
        <li><strong>Hyperparameter Tuning:</strong> Utilizes GridSearchCV to optimize model parameters, ensuring the best performance for the ensemble model.</li>
        
        <li><strong>Model Evaluation:</strong> Evaluates model performance using metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared, ensuring robust predictions.</li>

        <li><strong>Data Pipeline:</strong> Cleans and transforms raw gemstone data, applying techniques like imputation, scaling, and categorical encoding.</li>
          
        <li><strong>Modeling:</strong> Utilizes advanced regression models, including CatBoost, XGBoost, and KNN, combined through a Voting Regressor to improve predictive accuracy. Hyperparameter tuning and model evaluation are performed to select the best ensemble.</li>
          
        <li><strong>Deployment:</strong> The application is deployed on AWS Elastic Beanstalk with a REST API for integration and testing.</li>
          
        <li><strong>Web Application:</strong> Provides an interactive Flask-based web interface where users can input gemstone features and instantly receive a price prediction.</li>
          
        <li><strong>Explainability:</strong> Integrates LIME for model interpretation to help users understand the factors influencing predictions.</li>
        
        <li><strong>Performance:</strong> Achieved accuracy of 98%.</li>
      </ul>  
      
        <p><strong>Tools:</strong>Data Ingestion, EDA, Visualization, Probability&Statistics, Feature Engineering, Feature Scaling, Feature Selection, Data Preprocessing, Python Libraries, Machine Learning, AWS Cloud Deployement.</p>
        
        <div class="project-links">
        <a href="https://github.com/ManojRam7/GEMSTONES_PRICE_PREDICTOR" target="_blank" class="project-btn">Source Code</a>
      </div>
      </div>

      <!-- --------------------------------------------------------------  -->

      <div class="project-card" data-aos="fade-up">
        <img src="assets/project2.png" alt="Project Image">
        <h3>Real Estate Investment Analytics System</h3>
        <h4><strong>Business Impact Summary:</strong></h4>
        <p>Developed a machine learning web application designed to estimate house prices in the Boston area based on multiple property features. Leveraging regression techniques and an ensemble of advanced models (including CatBoost, XGBoost, and KNN), this project guides users through predicting home values by inputting relevant attributes such as crime rate, number of rooms, tax rate, and more.</p>
        <ul>
          <h4><strong>Technical Features:</strong></h4>
          <li><strong>Data Ingestion:</strong> Loads and splits real-world housing data for training and testing.</li>
          <li><strong>Exploratory Data Analysis (EDA):</strong> Conducts thorough EDA to understand data distributions, relationships, and potential outliers, using visualizations like scatter plots, histograms, and box plots.</li>
          <li><strong>Feature Engineering:</strong> Implements feature engineering techniques to create new features and applies transformations to improve model performance.</li>
          <li><strong>Data Preprocessing:</strong> Handles missing values, scales numerical features, and encodes categorical variables to prepare the dataset for modeling.</li>
          <li><strong>Model Training:</strong> Employs a variety of regression algorithms, including CatBoost, XGBoost, and KNN, to predict house prices. These models are combined using a Voting Regressor to enhance accuracy.</li>
          <li><strong>Hyperparameter Tuning:</strong> Utilizes GridSearchCV to optimize model parameters, ensuring the best performance for the ensemble model.</li>
          <li><strong>Model Evaluation:</strong> Evaluates model performance using metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared, ensuring robust predictions.</li>
          <li><strong>Web Application:</strong> Features both Flask and Streamlit interfaces, allowing users to input data via a user-friendly form and instantly receive price predictions</li>
          <li><strong>Model Serialization:</strong> The trained models and scalers are saved as pickle files for deployment.</li>
          <li><strong>API Integration:</strong> The Flask app exposes a /predict_api endpoint for programmatic prediction.</li>
          <li><strong>Comprehensive User Input:</strong> Supports detailed input for all relevant property features, ensuring accurate and personalized predictions.</li>
          <li><strong>Performance:</strong> Achieved accuracy of 99%.</li>
        </ul>

        <p><strong>Tools:</strong>Data Ingestion, EDA, Data Preprocessing, Visualization, Python Libraries, Machine Learning, Streamlit Community Cloud.</p>
        
        <div class="project-links">
          <a href="https://boston-houseprice-predictor.streamlit.app" target="_blank" class="project-btn">STREAMLIT APP</a>
          <a href="https://github.com/ManojRam7/BostonHousePrice_Predictor" target="_blank" class="project-btn">Source Code</a>
        </div>
      </div>


      <!-- --------------------------------------------------------------  -->
      
      
      <div class="project-card" data-aos="fade-up">
        <img src="assets/project4.png" alt="Project Image">
        <h3>Clinical Decision Support System for Cancer Screening</h3>
        <h4><strong>Business Impact Summary:</strong></h4>
        <p>Developed a deep learning application that predicts breast cancer from medical data, assisting healthcare professionals with early diagnosis and effective patient management. Leveraging advanced machine learning techniques and neural networks, this project streamlines the process of identifying the likelihood of breast cancer based on clinical features, providing rapid and accurate predictions for practical healthcare use.</p>
        <ul>
          <h4><strong>Technical Features:</strong></h4>
          <li><strong>Data Ingestion:</strong> Loads and preprocesses real-world breast cancer datasets for robust model training and testing.</li> 
          
          <li><strong>Dataset Preparation:</strong> Utilizes comprehensive datasets with features relevant to breast cancer diagnosis, such as cell characteristics and biopsy data.</li>
          
          <li><strong>Exploratory Data Analysis (EDA):</strong> Performs EDA to understand feature distributions, correlations, and visualize data patterns.</li> 
          
          <li><strong>Data Preprocessing:</strong> Applies normalization, scaling, and feature engineering to improve model performance.</li>
          
          <li><strong>Model Training:</strong> Implements state-of-the-art neural networks and machine learning algorithms (e.g., logistic regression, random forest, CNNs) to classify cases as malignant or benign.</li> 
          
          <li><strong>Performance Visualization:</strong> Visualizes training and validation accuracy/loss curves, ROC curves, and confusion matrices to evaluate model effectiveness.</li> 
          
          <li><strong>Interactive Notebooks:</strong> Jupyter Notebooks provide step-by-step documentation, code, and visualizations for transparency and reproducibility.</li> 
          
          <li><strong>Result Interpretation:</strong> Offers clear output of predicted cancer status along with confidence scores for each prediction.</li> 
          
          <li><strong>Export and Deployment:</strong> Supports exporting trained models for deployment in real-world or mobile applications.</li> 
          
          <li><strong>Performance:</strong> Achieved accuracy of 97%.</li>
        </ul>

        <p><strong>Tools:</strong>Jupyter Notebook, Python, TensorFlow/Keras (or PyTorch), Scikit-Learn, Data Visualization, NumPy, Matplotlib/Seaborn, Machine Learning, Deep Learning, Streamlit Community Cloud.</p>
        
        <div class="project-links">
          <a href="https://breastcancerpredictor-app.streamlit.app" target="_blank" class="project-btn">STREAMLIT APP</a>
          <a href="https://github.com/ManojRam7/BreastCancer_Predictor" target="_blank" class="project-btn">Source Code</a>
        </div>
      </div>


      <!-- --------------------------------------------------------------  -->


      <div class="project-card" data-aos="fade-up">
        <img src="assets/project7.png" alt="Project Image">
        <h3>Educational Analytics & Performance Optimization System</h3>
        <h4><strong>Business Impact Summary:</strong></h4>
        <p>Developed a machine learning-based application to predict student academic performance, enabling educators and institutions to identify at-risk students early and implement targeted interventions. By leveraging advanced data analytics and predictive modeling, this project streamlines the evaluation of student outcomes based on a variety of academic and socio-demographic factors, facilitating data-driven decisions for improved educational management and student success.</p>      
        <ul> <h4><strong>Technical Features:</strong></h4> 
          <li><strong>Data Ingestion:</strong> Efficiently loads and preprocesses real-world student datasets from diverse sources for robust model training and evaluation.</li> 
          <li><strong>Dataset Preparation:</strong> Utilizes comprehensive educational datasets with features such as grades, attendance, parental background, and study habits relevant to academic performance prediction.</li>
          <li><strong>Exploratory Data Analysis (EDA):</strong> Performs in-depth EDA to understand feature significance, uncover data trends, and visualize relationships affecting student outcomes.</li> 
          <li><strong>Data Preprocessing:</strong> Implements normalization, encoding, and feature selection/engineering to enhance model accuracy and reliability.</li> 
          <li><strong>Model Training:</strong> Applies a range of machine learning algorithms (e.g., logistic regression, decision trees, random forest, neural networks) to classify student performance levels or predict grades.</li> 
          <li><strong>Performance Visualization:</strong> Visualizes model training/validation metrics, confusion matrices, and feature importances for comprehensive performance evaluation.</li> 
          <li><strong>Interactive Notebooks:</strong> Jupyter Notebooks provide transparent, step-by-step analysis with code, commentary, and visualizations to enhance reproducibility and ease of understanding.</li> 
          <li><strong>Result Interpretation:</strong> Delivers interpretable prediction outputs, including probability/confidence scores, to aid actionable insights for educators.</li> 
          <li><strong>Export and Deployment:</strong> Supports exporting trained models for integration into educational platforms or deployment via web applications.</li> 
          <li><strong>Performance:</strong> Achieved accuracy of 97%.</li>
        </ul>

        <p> <strong>Tools:</strong> Jupyter Notebook, Python, Scikit-Learn, NumPy, Pandas, Matplotlib/Seaborn, Machine Learning, Data Visualization, Streamlit Community Cloud. </p>
        
        <div class="project-links">
          <a href="https://github.com/ManojRam7/StudentPerformance_Predictor" target="_blank" class="project-btn">Source Code</a>
        </div>
      </div>

     

      <!--
      <div class="project-card" data-aos="fade-up">
        <img src="assets/project5.png" alt="Project Image">
        <h3>Portfolio</h3>
        <h4><strong>Project Summary:</strong></h4>
        <p>Developed a personal portfolio website to showcase my skills, projects, and professional journey. This project highlights my expertise in data science, machine learning, and software development, providing a platform for potential employers and collaborators to explore my work.</p>
        <ul>
          <h4><strong>Technical Features:</strong></h4>
          <li><strong>Responsive Design:</strong> Built with a mobile-first approach, ensuring optimal viewing across devices.</li>
          <li><strong>Project Showcase:</strong> Displays a curated selection of my projects with detailed descriptions, technologies used, and links to live demos and source code.</li>
          <li><strong>About Me Section:</strong> Provides an overview of my background, skills, and professional journey in data science and software development.</li>
          <li><strong>Contact Form:</strong> Allows visitors to reach out for collaboration or inquiries directly through the website.</li>
          <li><strong>Technologies Used:</strong> HTML, CSS, JavaScript for responsive design, and GitHub Pages for hosting.</li>
        </ul>
        <p><strong>Tools:</strong>HTML, CSS, JavaScript, GitHub Pages.</p>
        <p><strong>Live Demo:</strong> The portfolio is hosted on GitHub Pages, providing a seamless experience for visitors to explore my work.</p>
        <div class="project-links">
        <a href="https://github.com/ManojRam7/RamMopatisPortfolio" target="_blank" class="project-btn">Project Repository</a>        
      </div>
      -->
    </div>
  </section>

      


  <section id="resume" class="section">
    <h2 data-aos="fade-up">Resume</h2>
    <p data-aos="fade-up">Want to know more about my job and education? Download my resume to get the complete details.</p>
    <a href="assets/resume.pdf" class="btn" download>Download Resume</a>
  </section>

    <!-- --------------------------------------------------------------  -->

  <section id="contact" class="section">
    <h2 data-aos="fade-up">Contact Me</h2>
    <p data-aos="fade-up">Feel free to reach out to me through the following platforms:</p>
    <div class="contact-links" data-aos="fade-up">
      <a href="https://www.linkedin.com/in/manojrammopati202095187/" target="_blank" class="contact-link"><i class="fab fa-linkedin"></i> LinkedIn</a>
      <a href="mailto:manojrammopati@gmail.com" class="contact-link"><i class="fas fa-envelope"></i> Email</a>
      <a href="mailto:manojrammopati@outlook.com" class="contact-link"><i class="fas fa-envelope"></i> Outlook</a>
      <a href="https://github.com/ManojRam7" target="_blank" class="contact-link"><i class="fab fa-github"></i> GitHub</a>
    </div>
  </section>

    <!-- --------------------------------------------------------------  -->

  <footer>
    <p>&copy; 2024 Ram Mopati. All rights reserved.</p>
  </footer>
   
    <!-- --------------------------------------------------------------  -->
  <!-- Scripts -->
   -- Scripts for AOS and smooth scrolling -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/js/all.min.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/aos/2.3.4/aos.js"></script>
  <script>
    AOS.init({
      duration: 800, // Animation duration in ms
      offset: 120,   // Animation offset in px
    });

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        document.querySelector(this.getAttribute('href')).scrollIntoView({
          behavior: 'smooth',
          block: 'start',
        });
      });
    });

    document.querySelectorAll('.contact-link').forEach(link => {
      link.addEventListener('mouseover', function () {
        const tooltip = document.createElement('div');
        tooltip.className = 'tooltip';
        tooltip.textContent = this.textContent.trim();
        document.body.appendChild(tooltip);
        const rect = this.getBoundingClientRect();
        tooltip.style.left = `${rect.left + rect.width / 2 - tooltip.offsetWidth / 2}px`;
        tooltip.style.top = `${rect.top - 30}px`;

        this.addEventListener('mouseleave', () => tooltip.remove());
      });
    });

    const buttons = document.querySelectorAll('.btn');
    buttons.forEach(button => {
      button.addEventListener('mouseenter', () => {
        button.style.transform = 'scale(1.1)';
        button.style.transition = 'transform 0.3s ease';
      });
      button.addEventListener('mouseleave', () => {
        button.style.transform = 'scale(1)';
      });
    });
  </script>
</body>
</html>
